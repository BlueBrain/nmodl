include:
  - project: hpc/gitlab-pipelines
    file:
      - spack-build-components.gitlab-ci.yml
      - github-project-pipelines.gitlab-ci.yml
  - project: hpc/gitlab-upload-logs
    file: enable-upload.yml

trigger cvf:
  stage: .pre
  rules:
    # Don't run on PRs targeting the LLVM development branch
    - if: '$CI_EXTERNAL_PULL_REQUEST_TARGET_BRANCH_NAME == "llvm"'
      when: never
    # Otherwise always run this
    - when: always
  trigger:
    project: hpc/cvf
    # Make the NMODL CI status depend on the CVF CI status
    strategy: depend
  variables:
    # Tell CVF to use the same commits/branches as NMODL.
    SPACK_ENV_FILE_URL: $SPACK_SETUP_COMMIT_MAPPING_URL

.spack_nmodl:
  variables:
    SPACK_PACKAGE: nmodl
    SPACK_PACKAGE_SPEC: ~legacy-unit+python+llvm
    SPACK_INSTALL_EXTRA_FLAGS: -v

spack_setup:
  extends: .spack_setup_ccache
  variables:
    NMODL_COMMIT: ${CI_COMMIT_SHA}
    # Enable fetching GitHub PR descriptions and parsing them to find out what
    # branches to build of other projects.
    PARSE_GITHUB_PR_DESCRIPTIONS: "true"

build:intel:
  extends:
    - .spack_build
    - .spack_nmodl
  variables:
    SPACK_PACKAGE_COMPILER: intel

.nmodl_tests:
  variables:
    # https://github.com/BlueBrain/nmodl/issues/737
    bb5_ntasks: 1

test:intel:
  extends:
    - .ctest
    - .nmodl_tests
  needs: ["build:intel"]

.benchmark_config:
  variables:
    bb5_ntasks: 1
    bb5_cpus_per_task: 1
    bb5_memory: 16G
    bb5_exclusive: full
    bb5_constraint: gpu_32g # CascadeLake CPU & V100 GPU node

.build_allocation:
  variables:
    bb5_ntasks: 2   # so we block 16 cores
    bb5_cpus_per_task: 8 # ninja -j {this}
    bb5_memory: 76G # ~16*384/80

build_cuda:gcc:
  extends: [.spack_build, .build_allocation]
  variables:
    SPACK_PACKAGE: nmodl
    SPACK_PACKAGE_SPEC: ~legacy-unit+python+llvm+llvm_cuda
    SPACK_INSTALL_EXTRA_FLAGS: -v
    SPACK_PACKAGE_COMPILER: gcc

test_benchmark:
  extends:
    - .benchmark_config
    - .ctest
  needs: ["build_cuda:gcc"]
